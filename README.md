# xNN_math

o Using layers to map input data to features to classes
o Computing an error by generating a class pdf and comparing it with the true pdf
o Back propagating the sensitivity of the error with respect to feature maps
o Computing the sensitivity of the error with respect to parameters
o Updating the parameters to minimize the error

Put theory to practice and write Python (with NumPy) code to
mimic a simple / lite / reduced functionality PyTorch library and demonstrate is use in the
design and training of a simple neural network for MNIST image classification
On top of that, adding software enhancements that mimic those commonly found in
professional xNN libraries and demonstrate their use in the design and training of the
same simple neural network for MNIST image classification
